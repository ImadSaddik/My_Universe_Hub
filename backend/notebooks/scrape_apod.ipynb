{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "for model in genai.list_models():\n",
        "    pprint.pprint(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "html_code_to_process = textwrap.dedent(\"\"\"\n",
        "    <center>\n",
        "    <b> A Double Detonation Supernova </b> <br>\n",
        "    <b> Image Credit: </b>\n",
        "    <a href=\"https://www.eso.org/\">ESO</a>,\n",
        "    <a href=\"https://www.unsw.edu.au/hdr/priyam-das\">P. Das</a> et al.;\n",
        "    Background stars\n",
        "    (<a href=\"https://www.nasa.gov/\">NASA</a>/<a href=\"https://science.nasa.gov/mission/hubble/\">Hubble</a>): K. Noll et al.\n",
        "    </center>\n",
        "    \"\"\")\n",
        "\n",
        "system_prompt = textwrap.dedent(f\"\"\"\n",
        "    You are an expert text extraction AI. Your sole purpose is to extract author and credit information from a snippet of HTML code.\n",
        "\n",
        "    Follow these rules precisely:\n",
        "    1.  Find the text that comes **after** the \"Image Credit\" or \"Illustration Credit\" line.\n",
        "    2.  Extract all names and sources, including the text inside `<a>` tags.\n",
        "    3.  Combine everything into a **single string**.\n",
        "    4.  Replace any semicolons (`;`) with commas (`,`).\n",
        "\n",
        "    **CRITICAL:** Your response must **only** be the final extracted string. Do not write explanations, code, or any other text.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### Example 1\n",
        "\n",
        "    **Input HTML:**\n",
        "    ```html\n",
        "    <center>\n",
        "    <b> The Great Globular Cluster in Hercules </b> <br/>\n",
        "    <b>Image Credit &amp;\n",
        "    <a href=\"lib/about_apod.html#srapply\">Copyright</a>:</b>\n",
        "    <a href=\"[https://www.distant-luminosity.com/about.html](https://www.distant-luminosity.com/about.html)\">Jan Beckmann, Julian Zoller, Lukas Eisert, Wolfgang Hummel</a>\n",
        "    </center>\n",
        "    ````\n",
        "\n",
        "    **Output:**\n",
        "    `Jan Beckmann, Julian Zoller, Lukas Eisert, Wolfgang Hummel`\n",
        "\n",
        "    -----\n",
        "\n",
        "    ### Example 2\n",
        "\n",
        "    **Input HTML:**\n",
        "\n",
        "    ```html\n",
        "    <center>\n",
        "    <b> NGC 602: Oyster Star Cluster </b> <br>\n",
        "    <b> Image Credit: </b>\n",
        "    X-ray: Chandra: NASA/CXC/Univ.Potsdam/L.Oskinova et al; <br>\n",
        "    Optical: Hubble: NASA/STScI; Infrared: Spitzer: NASA/JPL-Caltech\n",
        "    </center>\n",
        "    ```\n",
        "\n",
        "    **Output:**\n",
        "    `X-ray: Chandra: NASA/CXC/Univ.Potsdam/L.Oskinova et al, Optical: Hubble: NASA/STScI, Infrared: Spitzer: NASA/JPL-Caltech`\n",
        "\n",
        "    -----\n",
        "\n",
        "    Now, process the following HTML.\n",
        "\n",
        "    **Input HTML:**\n",
        "\n",
        "    ```html\n",
        "    {html_code_to_process}\n",
        "    ```\n",
        "\n",
        "    **Output:**\n",
        "    \"\"\")\n",
        "\n",
        "response = model.generate_content(system_prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def scrapeAPODWebsite():\n",
        "    print(\"Scraping the APOD website.\")\n",
        "    createOutputFileIfNotExists()\n",
        "\n",
        "    a_tags = get_a_tags()\n",
        "    start_time = time.time()\n",
        "    rpm_counter = 0\n",
        "    for tag in tqdm(a_tags, total=len(a_tags)):\n",
        "        try:\n",
        "            item = scrape_a_tag(tag)\n",
        "            if item[\"image_url\"] is None:\n",
        "                # This means that this is a video link, we don't want to include it\n",
        "                continue\n",
        "\n",
        "            with open(\"../data/apod_data.json\", \"r\") as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "            if itemExistsInData(data, item):\n",
        "                print(f\"Item for date {item['date']} already exists in the data. Stop scraping.\")\n",
        "                break\n",
        "            else:\n",
        "                data.append(item)\n",
        "\n",
        "            # Write the updated data back to the file\n",
        "            with open(\"../data/apod_data.json\", \"w\") as file:\n",
        "                json.dump(data, file, indent=4)\n",
        "            # to avoid hitting the rate limit of 15 requests per minute\n",
        "            end_time = time.time()\n",
        "            if end_time - start_time < 60:\n",
        "                rpm_counter += 1\n",
        "                if rpm_counter == 10:  # 10 requests per minute just to leave a margin\n",
        "                    time.sleep(60)\n",
        "                    rpm_counter = 0\n",
        "                    start_time = time.time()\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while scraping: {e}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "def createOutputFileIfNotExists():\n",
        "    if not os.path.exists(\"../data/apod_data.json\"):\n",
        "        with open(\"../data/apod_data.json\", \"w\") as file:\n",
        "            file.write(\"[]\")\n",
        "\n",
        "\n",
        "def get_a_tags():\n",
        "    source = requests.get(\"https://apod.nasa.gov/apod/archivepix.html\").text\n",
        "    soup = BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    b_tag = soup.find_all(\"b\")[1]\n",
        "    return b_tag.find_all(\"a\")\n",
        "\n",
        "\n",
        "def scrape_a_tag(a_tag):\n",
        "    dictionary = {}\n",
        "\n",
        "    date = a_tag.find_previous(string=True).strip()\n",
        "    title = a_tag.text.strip()\n",
        "    url = f\"https://apod.nasa.gov/apod/{a_tag['href']}\"\n",
        "    image, explanation = get_image_and_explanation(url)\n",
        "    authors = get_authors(url)\n",
        "\n",
        "    dictionary[\"date\"] = date\n",
        "    dictionary[\"title\"] = title\n",
        "    dictionary[\"url\"] = url\n",
        "    dictionary[\"image_url\"] = image\n",
        "    dictionary[\"explanation\"] = explanation\n",
        "    dictionary[\"authors\"] = authors\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def get_image_and_explanation(url):\n",
        "    source = requests.get(url).text\n",
        "    soup = BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    p_tags = soup.find_all(\"p\")\n",
        "    img_tag = soup.find(\"img\")\n",
        "    explanation = p_tags[2].get_text()\n",
        "\n",
        "    try:\n",
        "        img_url = f\"https://apod.nasa.gov/apod/{img_tag['src']}\"\n",
        "    except Exception:\n",
        "        img_url = None\n",
        "\n",
        "    return img_url, explanation\n",
        "\n",
        "\n",
        "def get_authors(url):\n",
        "    source = requests.get(url).text\n",
        "    soup = BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    center_tags = soup.find_all(\"center\")\n",
        "    credit_center_tag = center_tags[1]\n",
        "    authors = extract_authors_with_gemini(credit_center_tag)\n",
        "\n",
        "    return authors\n",
        "\n",
        "\n",
        "def extract_authors_with_gemini(html_code_to_process):\n",
        "    system_prompt = textwrap.dedent(f\"\"\"\n",
        "    You are an expert text extraction AI. Your sole purpose is to extract author and credit information from a snippet of HTML code.\n",
        "\n",
        "    Follow these rules precisely:\n",
        "    1.  Find the text that comes **after** the \"Image Credit\" or \"Illustration Credit\" line.\n",
        "    2.  Extract all names and sources, including the text inside `<a>` tags.\n",
        "    3.  Combine everything into a **single string**.\n",
        "    4.  Replace any semicolons (`;`) with commas (`,`).\n",
        "\n",
        "    **CRITICAL:** Your response must **only** be the final extracted string. Do not write explanations, code, or any other text.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### Example 1\n",
        "\n",
        "    **Input HTML:**\n",
        "    ```html\n",
        "    <center>\n",
        "    <b> The Great Globular Cluster in Hercules </b> <br/>\n",
        "    <b>Image Credit &amp;\n",
        "    <a href=\"lib/about_apod.html#srapply\">Copyright</a>:</b>\n",
        "    <a href=\"[https://www.distant-luminosity.com/about.html](https://www.distant-luminosity.com/about.html)\">Jan Beckmann, Julian Zoller, Lukas Eisert, Wolfgang Hummel</a>\n",
        "    </center>\n",
        "    ````\n",
        "\n",
        "    **Output:**\n",
        "    `Jan Beckmann, Julian Zoller, Lukas Eisert, Wolfgang Hummel`\n",
        "\n",
        "    -----\n",
        "\n",
        "    ### Example 2\n",
        "\n",
        "    **Input HTML:**\n",
        "\n",
        "    ```html\n",
        "    <center>\n",
        "    <b> NGC 602: Oyster Star Cluster </b> <br>\n",
        "    <b> Image Credit: </b>\n",
        "    X-ray: Chandra: NASA/CXC/Univ.Potsdam/L.Oskinova et al; <br>\n",
        "    Optical: Hubble: NASA/STScI; Infrared: Spitzer: NASA/JPL-Caltech\n",
        "    </center>\n",
        "    ```\n",
        "\n",
        "    **Output:**\n",
        "    `X-ray: Chandra: NASA/CXC/Univ.Potsdam/L.Oskinova et al, Optical: Hubble: NASA/STScI, Infrared: Spitzer: NASA/JPL-Caltech`\n",
        "\n",
        "    -----\n",
        "\n",
        "    Now, process the following HTML.\n",
        "\n",
        "    **Input HTML:**\n",
        "\n",
        "    ```html\n",
        "    {html_code_to_process}\n",
        "    ```\n",
        "\n",
        "    **Output:**\n",
        "    \"\"\")\n",
        "\n",
        "    model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
        "    response = model.generate_content(system_prompt)\n",
        "    return response.text\n",
        "\n",
        "\n",
        "def convert_date(date):\n",
        "    date = date.replace(\":\", \"\")\n",
        "    return datetime.strptime(date, \"%Y %B %d\").date()\n",
        "\n",
        "\n",
        "def itemExistsInData(data, item):\n",
        "    for entry in data:\n",
        "        if entry[\"date\"] == item[\"date\"]:\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scrapeAPODWebsite()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "apod",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
